{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Use 3-Level Relevance Generation (RG-3L) from \"Beyond Yes and No: Improving Zero-Shot LLM Rankers via Scoring Fine-Grained Relevance Labels\"**\n",
    "- **Allow for multiple Evidence citations**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prospectus ID</th>\n",
       "      <th>Original Filename</th>\n",
       "      <th>Section ID</th>\n",
       "      <th>Section Title</th>\n",
       "      <th>Subsection ID</th>\n",
       "      <th>Subsection Title</th>\n",
       "      <th>Subsubsection ID</th>\n",
       "      <th>Subsubsection Title</th>\n",
       "      <th>Subsubsection Text</th>\n",
       "      <th>Market Dynamics - a</th>\n",
       "      <th>Market Dynamics - b</th>\n",
       "      <th>Market Dynamics - c</th>\n",
       "      <th>Parsing Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235</td>\n",
       "      <td>Final Offerings 2020.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>RISK FACTORS</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_An investment in the Notes involves a high de...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Final Offerings 2020.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>RISK FACTORS</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Risks Relating to the Group’s Business, Techno...</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>The Group faces significant competition in eac...</td>\n",
       "      <td>The French telecommunications market is a matu...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>Final Offerings 2020.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>RISK FACTORS</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Risks Relating to the Group’s Business, Techno...</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>The deployment of fiber optic networks and/or ...</td>\n",
       "      <td>The Group believes that one of its major compe...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>Final Offerings 2020.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>RISK FACTORS</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Risks Relating to the Group’s Business, Techno...</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>Changes in competitive offerings for content, ...</td>\n",
       "      <td>The market for content is intensely competitiv...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prospectus ID         Original Filename Section ID Section Title  \\\n",
       "0           235  Final Offerings 2020.pdf          1  RISK FACTORS   \n",
       "1            16  Final Offerings 2020.pdf          1  RISK FACTORS   \n",
       "2            16  Final Offerings 2020.pdf          1  RISK FACTORS   \n",
       "3            16  Final Offerings 2020.pdf          1  RISK FACTORS   \n",
       "\n",
       "  Subsection ID                                   Subsection Title  \\\n",
       "0           1.1                                                NaN   \n",
       "1           1.1  Risks Relating to the Group’s Business, Techno...   \n",
       "2           1.1  Risks Relating to the Group’s Business, Techno...   \n",
       "3           1.1  Risks Relating to the Group’s Business, Techno...   \n",
       "\n",
       "  Subsubsection ID                                Subsubsection Title  \\\n",
       "0            1.1.1                                                NaN   \n",
       "1            1.1.1  The Group faces significant competition in eac...   \n",
       "2            1.1.2  The deployment of fiber optic networks and/or ...   \n",
       "3            1.1.3  Changes in competitive offerings for content, ...   \n",
       "\n",
       "                                  Subsubsection Text Market Dynamics - a  \\\n",
       "0  _An investment in the Notes involves a high de...                <NA>   \n",
       "1  The French telecommunications market is a matu...                <NA>   \n",
       "2  The Group believes that one of its major compe...                <NA>   \n",
       "3  The market for content is intensely competitiv...                <NA>   \n",
       "\n",
       "  Market Dynamics - b Market Dynamics - c Parsing Error  \n",
       "0                <NA>                <NA>           NaN  \n",
       "1                <NA>                <NA>           NaN  \n",
       "2                <NA>                <NA>           NaN  \n",
       "3                <NA>                <NA>           NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Check if processed file exists\n",
    "if os.path.exists('prospectuses_data_processed.csv'):\n",
    "    df = pd.read_csv('prospectuses_data_processed.csv')\n",
    "else:\n",
    "    df = pd.read_csv('../data/prospectuses_data.csv')\n",
    "    # Filter out rows that have \"failed parsing\" in the Section ID column\n",
    "    df = df[df['Section ID'] != \"failed parsing\"]\n",
    "    \n",
    "df = pd.read_csv('../data/prospectuses_data.csv')\n",
    "\n",
    "# Filter out rows that have \"failed parsing\" in the Section ID column\n",
    "df = df[df['Section ID'] != \"failed parsing\"]\n",
    "\n",
    "\n",
    "questions = {\n",
    "    \"Market Dynamics - a\": \"Is the company exposed to risks associated with cyclical products?\",\n",
    "    \"Market Dynamics - b\": \"Does the text mention risks related to demographic or structural trends affecting the market?\",\n",
    "    \"Market Dynamics - c\": \"Does the text discuss risks due to seasonal volatility in the industry?\"\n",
    "}\n",
    "\n",
    "# Define the questions corresponding to each column\n",
    "questions_original = {\n",
    "    \"Market Dynamics - a\": \"Exposure to cyclical products\",\n",
    "    \"Market Dynamics - b\": \"Impact of demographic and structural trends\",\n",
    "    \"Market Dynamics - c\": \"Seasonal industry volatility\"\n",
    "}\n",
    "\n",
    "# Ensure the relevance and evidence columns are created with a compatible data type\n",
    "for column_name in questions.keys():\n",
    "    if column_name in df.columns:\n",
    "        df[column_name] = df[column_name].astype('string')\n",
    "    else:\n",
    "        df[column_name] = \"\"\n",
    "\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields(response):\n",
    "    # Remove any newlines and extra spaces\n",
    "    response = ' '.join(response.strip().split())\n",
    "\n",
    "    # Extract the Relevance field\n",
    "    relevance_match = re.search(r'\"Relevance\"\\s*:\\s*\"([^\"]+)\"', response)\n",
    "    if relevance_match:\n",
    "        relevance = relevance_match.group(1).strip()\n",
    "    else:\n",
    "        relevance = \"Parsing Error\"\n",
    "\n",
    "    # Extract the Evidence field(s)\n",
    "    evidence_match = re.search(r'\"Evidence\"\\s*:\\s*(.+?)(?:,?\\s*\"[^\"]+\"\\s*:|\\s*}$)', response)\n",
    "    if evidence_match:\n",
    "        evidence_str = evidence_match.group(1).strip()\n",
    "        # Remove any trailing commas or braces\n",
    "        evidence_str = evidence_str.rstrip(', }')\n",
    "        # Split the evidence_str into individual evidence items\n",
    "        # Evidence items are strings enclosed in double quotes\n",
    "        evidence_items = re.findall(r'\"([^\"]+)\"', evidence_str)\n",
    "        evidence = evidence_items\n",
    "    else:\n",
    "        evidence = []\n",
    "\n",
    "    return relevance, evidence\n",
    "\n",
    "\n",
    "def analyze_prospectus_row_single_question(row, question):\n",
    "    # System and user prompts\n",
    "    system_prompt = \"You are an expert in analyzing bond prospectuses and identifying specific risk factors.\"\n",
    "\n",
    "    # Format the user prompt using the row's data\n",
    "    prompt = f\"\"\"\n",
    "{system_prompt}\n",
    "\n",
    "For the following question and text, judge whether the text is \"Highly Relevant\", \"Somewhat Relevant\", or \"Not Relevant\".\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Text:\n",
    "Subsubsection Title: {row['Subsubsection Title']}\n",
    "Subsubsection Text: {row['Subsubsection Text']}\n",
    "\n",
    "\n",
    "Please provide your answer in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"Highly Relevant\", \"Somewhat Relevant\", or \"Not Relevant\",\n",
    "  \"Evidence\": \"The exact phrases or sentences from the document that support your assessment; otherwise, leave blank.\"\n",
    "}}\n",
    "\n",
    "Note: Only provide the JSON response without any additional text.\n",
    "\"\"\"\n",
    "    # Run the prompt through the model\n",
    "    response = llm.invoke(input=prompt)\n",
    "\n",
    "    # Parse the response\n",
    "    try:\n",
    "        # Extract the Relevance and Evidence fields\n",
    "        relevance, evidence_list = extract_fields(response)\n",
    "        # Join multiple evidence items into a single string\n",
    "        evidence = '; '.join(evidence_list)\n",
    "    except Exception as e:\n",
    "        relevance = \"Parsing Error\"\n",
    "        evidence = \"\"\n",
    "\n",
    "    # Combine relevance and evidence\n",
    "    if relevance in [\"Highly Relevant\", \"Somewhat Relevant\"] and evidence:\n",
    "        combined_answer = f\"{relevance}: {evidence}\"\n",
    "    elif relevance in [\"Highly Relevant\", \"Somewhat Relevant\"]:\n",
    "        combined_answer = relevance\n",
    "    elif relevance == \"Not Relevant\":\n",
    "        combined_answer = \"Not Relevant\"\n",
    "    else:\n",
    "        combined_answer = \"Parsing Error\"\n",
    "\n",
    "    # For debugging\n",
    "    if combined_answer == \"Parsing Error\":\n",
    "        print(\"Parsing Error encountered. Response was:\")\n",
    "        print(response)\n",
    "\n",
    "    return combined_answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ -----------\n",
      "aiohappyeyeballs         2.4.3\n",
      "aiohttp                  3.10.10\n",
      "aiosignal                1.3.1\n",
      "annotated-types          0.7.0\n",
      "anyio                    4.6.2.post1\n",
      "appnope                  0.1.4\n",
      "asttokens                2.4.1\n",
      "async-timeout            4.0.3\n",
      "attrs                    24.2.0\n",
      "certifi                  2024.8.30\n",
      "charset-normalizer       3.4.0\n",
      "comm                     0.2.2\n",
      "debugpy                  1.8.8\n",
      "decorator                5.1.1\n",
      "exceptiongroup           1.2.2\n",
      "executing                2.1.0\n",
      "frozenlist               1.5.0\n",
      "h11                      0.14.0\n",
      "httpcore                 1.0.6\n",
      "httpx                    0.27.2\n",
      "idna                     3.10\n",
      "importlib_metadata       8.5.0\n",
      "ipykernel                6.29.5\n",
      "ipython                  8.29.0\n",
      "jedi                     0.19.2\n",
      "jsonpatch                1.33\n",
      "jsonpointer              3.0.0\n",
      "jupyter_client           8.6.3\n",
      "jupyter_core             5.7.2\n",
      "langchain                0.3.7\n",
      "langchain-core           0.3.17\n",
      "langchain-ollama         0.2.0\n",
      "langchain-text-splitters 0.3.2\n",
      "langsmith                0.1.142\n",
      "matplotlib-inline        0.1.7\n",
      "multidict                6.1.0\n",
      "nest_asyncio             1.6.0\n",
      "numpy                    1.26.4\n",
      "ollama                   0.3.3\n",
      "orjson                   3.10.11\n",
      "packaging                24.2\n",
      "pandas                   2.2.3\n",
      "parso                    0.8.4\n",
      "pexpect                  4.9.0\n",
      "pickleshare              0.7.5\n",
      "pip                      24.3.1\n",
      "platformdirs             4.3.6\n",
      "prompt_toolkit           3.0.48\n",
      "propcache                0.2.0\n",
      "psutil                   6.1.0\n",
      "ptyprocess               0.7.0\n",
      "pure_eval                0.2.3\n",
      "pydantic                 2.9.2\n",
      "pydantic_core            2.23.4\n",
      "Pygments                 2.18.0\n",
      "python-dateutil          2.9.0\n",
      "pytz                     2024.2\n",
      "PyYAML                   6.0.2\n",
      "pyzmq                    26.2.0\n",
      "requests                 2.32.3\n",
      "requests-toolbelt        1.0.0\n",
      "setuptools               75.3.0\n",
      "six                      1.16.0\n",
      "sniffio                  1.3.1\n",
      "SQLAlchemy               2.0.36\n",
      "stack-data               0.6.2\n",
      "tenacity                 9.0.0\n",
      "tornado                  6.4.1\n",
      "tqdm                     4.67.0\n",
      "traitlets                5.14.3\n",
      "typing_extensions        4.12.2\n",
      "tzdata                   2024.2\n",
      "urllib3                  2.2.3\n",
      "wcwidth                  0.2.13\n",
      "wheel                    0.45.0\n",
      "yarl                     1.17.1\n",
      "zipp                     3.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 32/74 [02:27<03:13,  4.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# Loop over each row in the DataFrame\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    for column_name, question in questions.items():\n",
    "        # Check if the answer column is already filled\n",
    "        if pd.notnull(df.at[index, column_name]) and df.at[index, column_name] != \"\":\n",
    "            # Skip processing this row for this question\n",
    "            continue\n",
    "        combined_answer = analyze_prospectus_row_single_question(row, question)\n",
    "        df.at[index, column_name] = combined_answer\n",
    "        \n",
    "    # Save progress every 50 rows\n",
    "    if index % 35 == 0 and index != 0:\n",
    "        df.to_csv('prospectuses_data_processed.csv', index=False)\n",
    "        # Remove the break statement to process all rows\n",
    "        break\n",
    "\n",
    "\n",
    "# Save the final DataFrame\n",
    "df.to_csv('prospectuses_data_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mester_nlp_mini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
