{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this Notebook we extract the remaining SubScore Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code to extract unique score combinations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_with_fundamental_score = pd.read_pickle('./rms_with_fundamental_score.pkl')\n",
    "rms_with_fundamental_score.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_score_combinations = rms_with_fundamental_score[['CategoryGroup', 'Category', 'TaggedCharacteristics']].drop_duplicates()\n",
    "# Replace all types of newlines and excessive whitespace in TaggedCharacteristics\n",
    "unique_score_combinations['TaggedCharacteristics'] = unique_score_combinations['TaggedCharacteristics'].str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "\n",
    "# Function to expand TaggedCharacteristics if it's a JSON string with multiple items\n",
    "def expand_tagged_characteristics(row):\n",
    "    try:\n",
    "        characteristics = json.loads(row['TaggedCharacteristics'])\n",
    "        if isinstance(characteristics, list):\n",
    "            # Replace newlines within each CharacteristicText\n",
    "            return pd.DataFrame([{\n",
    "                'CategoryGroup': row['CategoryGroup'],\n",
    "                'Category': row['Category'],\n",
    "                'TaggedCharacteristics': char['CharacteristicText'].replace('\\r', ' ').replace('\\n', ' '),\n",
    "                'CharacteristicInfluence': char.get('CharacteristicInfluence', None)  # Handle missing keys\n",
    "            } for char in characteristics])\n",
    "        else:\n",
    "            # If it's a single item or not a list, replace newlines if it's a string\n",
    "            if isinstance(characteristics, str):\n",
    "                characteristics = characteristics.replace('\\r', ' ').replace('\\n', ' ')\n",
    "            return pd.DataFrame([{\n",
    "                'CategoryGroup': row['CategoryGroup'],\n",
    "                'Category': row['Category'],\n",
    "                'TaggedCharacteristics': characteristics,\n",
    "                'CharacteristicInfluence': row.get('CharacteristicInfluence', None)\n",
    "            }])\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        # If parsing fails, replace newlines in the original TaggedCharacteristics\n",
    "        cleaned_text = row['TaggedCharacteristics'].replace('\\r', ' ').replace('\\n', ' ')\n",
    "        return pd.DataFrame([{\n",
    "            'CategoryGroup': row['CategoryGroup'],\n",
    "            'Category': row['Category'],\n",
    "            'TaggedCharacteristics': cleaned_text,\n",
    "            'CharacteristicInfluence': row.get('CharacteristicInfluence', None)\n",
    "        }])\n",
    "\n",
    "# Applying the function to each row and combining results\n",
    "expanded_unique_score_combinations = pd.concat(\n",
    "    unique_score_combinations.apply(expand_tagged_characteristics, axis=1).to_list(),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Sort, drop duplicates, and save to CSV\n",
    "unique_score_combinations = expanded_unique_score_combinations.sort_values(by=['CategoryGroup', 'Category', 'CharacteristicInfluence']).drop_duplicates()\n",
    "unique_score_combinations.to_csv('unique_score_combinations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the questions and instantiating the LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the questions corresponding to each column\n",
    "questions_market_dynamics = {\n",
    "    \"Market Dynamics - a\": \"Does the text mention that the company is exposed to risks associated with cyclical products?\",\n",
    "    \"Market Dynamics - b\": \"Does the text mention risks related to demographic or structural trends affecting the market?\",\n",
    "    \"Market Dynamics - c\": \"Does the text mention risks due to seasonal volatility in the industry?\"\n",
    "}\n",
    "questions_intra_industry_competition = {\n",
    "    \"Intra-Industry Competition - a\": \"Does the text mention that market pricing for the company's products or services is irrational or not based on fundamental factors?\",\n",
    "    \"Intra-Industry Competition - b\": \"Does the text mention that the market is highly fragmented with no clear leader or that there is only one dominant leader?\",\n",
    "    \"Intra-Industry Competition - c\": \"Does the text mention low barriers to entry in the industry, making it easy for new competitors to enter the market?\"\n",
    "}\n",
    "questions_regulatory_framework = {\n",
    "    \"Regulatory Framework - a\": \"Does the text mention that the industry is subject to a high degree of regulatory scrutiny?\",\n",
    "    \"Regulatory Framework - b\": \"Does the text mention a high dependency on regulation or being a beneficiary from regulation in an unstable regulatory environment?\"\n",
    "}\n",
    "questions_technology_risk = {\n",
    "    \"Technology Risk - a\": \"Does the text mention that the industry is susceptible to rapid technological advances or innovations?\",\n",
    "    \"Technology Risk - b\": \"Does the text mention that the company is perceived as a disruptor or is threatened by emerging technological changes?\"\n",
    "}\n",
    "\n",
    "all_question_dicts = [\n",
    "    questions_market_dynamics,\n",
    "    questions_intra_industry_competition,\n",
    "    questions_regulatory_framework,\n",
    "    questions_technology_risk\n",
    "]\n",
    "\n",
    "# Original questions\n",
    "questions_market_dynamics_original = {\n",
    "    \"Market Dynamics - a\": \"Exposure to cyclical products\",\n",
    "    \"Market Dynamics - b\": \"Impact of demographic and structural trends\",\n",
    "    \"Market Dynamics - c\": \"Seasonal industry volatility\"\n",
    "}\n",
    "questions_intra_industry_competition_original = {\n",
    "    \"Intra-Industry Competition - a\": \"Market pricing has not shown to be rational\",\n",
    "    \"Intra-Industry Competition - b\": \"Highly fragmented market with no clear leader or only one leader\",\n",
    "    \"Intra-Industry Competition - c\": \"Low barriers to entry\"\n",
    "}\n",
    "questions_regulatory_framework_original = {\n",
    "    \"Regulatory Framework - a\": \"Industry has high degree of regulatory scrutiny\",\n",
    "    \"Regulatory Framework - b\": \"High dependency on regulation or is a beneficiary from regulation in an unstable regulatory environment\"\n",
    "}\n",
    "questions_technology_risk_original = {\n",
    "    \"Technology Risk - a\": \"Industry susceptibility to technological advances\",\n",
    "    \"Technology Risk - b\": \"Company viewed as a disruptee/threatened by technological change\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prospectus ID</th>\n",
       "      <th>Original Filename</th>\n",
       "      <th>Section ID</th>\n",
       "      <th>Section Title</th>\n",
       "      <th>Subsection ID</th>\n",
       "      <th>Subsection Title</th>\n",
       "      <th>Subsubsection ID</th>\n",
       "      <th>Subsubsection Title</th>\n",
       "      <th>Subsubsection Text</th>\n",
       "      <th>Market Dynamics - a</th>\n",
       "      <th>Market Dynamics - b</th>\n",
       "      <th>Market Dynamics - c</th>\n",
       "      <th>Parsing Error</th>\n",
       "      <th>Intra-Industry Competition - a</th>\n",
       "      <th>Intra-Industry Competition - b</th>\n",
       "      <th>Intra-Industry Competition - c</th>\n",
       "      <th>Regulatory Framework - a</th>\n",
       "      <th>Regulatory Framework - b</th>\n",
       "      <th>Technology Risk - a</th>\n",
       "      <th>Technology Risk - b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235</td>\n",
       "      <td>Final Offerings 2020.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>RISK FACTORS</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_An investment in the Notes involves a high de...</td>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>Highly Relevant: the risks described below</td>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>Highly Relevant: Subsubsection Title: ... and ...</td>\n",
       "      <td>Highly Relevant</td>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>Not Relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Final Offerings 2020.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>RISK FACTORS</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Risks Relating to the Group’s Business, Techno...</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>The Group faces significant competition in eac...</td>\n",
       "      <td>The French telecommunications market is a matu...</td>\n",
       "      <td>Highly Relevant: Various evidence throughout t...</td>\n",
       "      <td>Highly Relevant</td>\n",
       "      <td>Highly Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Highly Relevant</td>\n",
       "      <td>Highly Relevant: ...the Group also competes wi...</td>\n",
       "      <td>Highly Relevant: The exact phrases or sentence...</td>\n",
       "      <td>Highly Relevant: Several evidence are presente...</td>\n",
       "      <td>Highly Relevant</td>\n",
       "      <td>Highly Relevant: This is a highly relevant ans...</td>\n",
       "      <td>Highly Relevant: The Group also faces competit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prospectus ID         Original Filename  Section ID Section Title  \\\n",
       "0           235  Final Offerings 2020.pdf           1  RISK FACTORS   \n",
       "1            16  Final Offerings 2020.pdf           1  RISK FACTORS   \n",
       "\n",
       "   Subsection ID                                   Subsection Title  \\\n",
       "0            1.1                                                NaN   \n",
       "1            1.1  Risks Relating to the Group’s Business, Techno...   \n",
       "\n",
       "  Subsubsection ID                                Subsubsection Title  \\\n",
       "0            1.1.1                                                NaN   \n",
       "1            1.1.1  The Group faces significant competition in eac...   \n",
       "\n",
       "                                  Subsubsection Text  \\\n",
       "0  _An investment in the Notes involves a high de...   \n",
       "1  The French telecommunications market is a matu...   \n",
       "\n",
       "                                 Market Dynamics - a  \\\n",
       "0                                       Not Relevant   \n",
       "1  Highly Relevant: Various evidence throughout t...   \n",
       "\n",
       "                          Market Dynamics - b Market Dynamics - c  \\\n",
       "0  Highly Relevant: the risks described below        Not Relevant   \n",
       "1                             Highly Relevant     Highly Relevant   \n",
       "\n",
       "   Parsing Error Intra-Industry Competition - a  \\\n",
       "0            NaN                   Not Relevant   \n",
       "1            NaN                Highly Relevant   \n",
       "\n",
       "                      Intra-Industry Competition - b  \\\n",
       "0                                       Not Relevant   \n",
       "1  Highly Relevant: ...the Group also competes wi...   \n",
       "\n",
       "                      Intra-Industry Competition - c  \\\n",
       "0                                       Not Relevant   \n",
       "1  Highly Relevant: The exact phrases or sentence...   \n",
       "\n",
       "                            Regulatory Framework - a Regulatory Framework - b  \\\n",
       "0  Highly Relevant: Subsubsection Title: ... and ...          Highly Relevant   \n",
       "1  Highly Relevant: Several evidence are presente...          Highly Relevant   \n",
       "\n",
       "                                 Technology Risk - a  \\\n",
       "0                                       Not Relevant   \n",
       "1  Highly Relevant: This is a highly relevant ans...   \n",
       "\n",
       "                                 Technology Risk - b  \n",
       "0                                       Not Relevant  \n",
       "1  Highly Relevant: The Group also faces competit...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the language model\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Check if the processed file exists; if not, process the raw data\n",
    "processed_file_path = '../data/prospectuses_data_processed.csv'\n",
    "raw_file_path = '../data/prospectuses_data.csv'\n",
    "\n",
    "# Check if processed file exists\n",
    "if os.path.exists(processed_file_path):\n",
    "    df = pd.read_csv(processed_file_path)\n",
    "else:\n",
    "    print(\"Processed file not found. Processing raw data...\")\n",
    "    df = pd.read_csv(raw_file_path)\n",
    "    # Filter out rows that have \"failed parsing\" in the Section ID column\n",
    "    df = df[df['Section ID'] != \"failed parsing\"]\n",
    "\n",
    "# Ensure the relevance and evidence columns are created with a compatible data type\n",
    "for question_dict in all_question_dicts:\n",
    "    # Iterate through each question key in the current dictionary\n",
    "    for column_name in question_dict.keys():\n",
    "        if column_name in df.columns:\n",
    "            df[column_name] = df[column_name].astype('string')\n",
    "        else:\n",
    "            df[column_name] = \"\"\n",
    "\n",
    "df.head(2)\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields(response):\n",
    "    # Remove any newlines and extra spaces\n",
    "    response = ' '.join(response.strip().split())\n",
    "\n",
    "    # Extract the Relevance field\n",
    "    relevance_match = re.search(r'\"Relevance\"\\s*:\\s*\"([^\"]+)\"', response)\n",
    "    if relevance_match:\n",
    "        relevance = relevance_match.group(1).strip()\n",
    "    else:\n",
    "        relevance = \"Parsing Error\"\n",
    "\n",
    "    # Extract the Evidence field(s)\n",
    "    evidence_match = re.search(r'\"Evidence\"\\s*:\\s*(.+?)(?:,?\\s*\"[^\"]+\"\\s*:|\\s*}$)', response)\n",
    "    if evidence_match:\n",
    "        evidence_str = evidence_match.group(1).strip()\n",
    "        # Remove any trailing commas or braces\n",
    "        evidence_str = evidence_str.rstrip(', }')\n",
    "        # Split the evidence_str into individual evidence items\n",
    "        # Evidence items are strings enclosed in double quotes\n",
    "        evidence_items = re.findall(r'\"([^\"]+)\"', evidence_str)\n",
    "        evidence = evidence_items\n",
    "    else:\n",
    "        evidence = []\n",
    "\n",
    "    return relevance, evidence\n",
    "\n",
    "\n",
    "def analyze_prospectus_row_single_question(row, question):\n",
    "    # System and user prompts\n",
    "    system_prompt = \"You are an expert in analyzing bond prospectuses and identifying specific risk factors.\"\n",
    "\n",
    "    # Format the user prompt using the row's data\n",
    "    prompt = f\"\"\"\n",
    "{system_prompt}\n",
    "\n",
    "For the following question and text, judge whether the text is \"Highly Relevant\", \"Somewhat Relevant\", or \"Not Relevant\".\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Text:\n",
    "Subsubsection Title: {row['Subsubsection Title']}\n",
    "Subsubsection Text: {row['Subsubsection Text']}\n",
    "\n",
    "\n",
    "Please provide your answer in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"Highly Relevant\", \"Somewhat Relevant\", or \"Not Relevant\",\n",
    "  \"Evidence\": \"The exact phrases or sentences from the document that support your assessment; otherwise, leave blank.\"\n",
    "}}\n",
    "\n",
    "Note: Only provide the JSON response without any additional text.\n",
    "\"\"\"\n",
    "    # Run the prompt through the model\n",
    "    response = llm.invoke(input=prompt)\n",
    "\n",
    "    # Parse the response\n",
    "    try:\n",
    "        # Extract the Relevance and Evidence fields\n",
    "        relevance, evidence_list = extract_fields(response)\n",
    "        # Join multiple evidence items into a single string\n",
    "        evidence = '; '.join(evidence_list)\n",
    "    except Exception as e:\n",
    "        relevance = \"Parsing Error\"\n",
    "        evidence = \"\"\n",
    "\n",
    "    # Combine relevance and evidence\n",
    "    if relevance in [\"Highly Relevant\", \"Somewhat Relevant\"] and evidence:\n",
    "        combined_answer = f\"{relevance}: {evidence}\"\n",
    "    elif relevance in [\"Highly Relevant\", \"Somewhat Relevant\"]:\n",
    "        combined_answer = relevance\n",
    "    elif relevance == \"Not Relevant\":\n",
    "        combined_answer = \"Not Relevant\"\n",
    "    else:\n",
    "        combined_answer = \"Parsing Error\"\n",
    "\n",
    "    # For debugging\n",
    "    if combined_answer == \"Parsing Error\":\n",
    "        print(\"Parsing Error encountered. Response was:\")\n",
    "        print(response)\n",
    "\n",
    "    return combined_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the LLM Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   0%|          | 10/7952 [00:01<17:34,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   0%|          | 20/7952 [01:30<33:32:14, 15.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   0%|          | 30/7952 [04:50<55:18:22, 25.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   1%|          | 40/7952 [07:56<42:39:27, 19.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   1%|          | 50/7952 [12:06<63:02:04, 28.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   1%|          | 58/7952 [14:31<36:21:16, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Error encountered. Response was:\n",
      "{\"Relevance\": \"Very Relevant\", \"Evidence\": \"net financial charges, which are defined as the portion of financial charges exceeding financial income, accrued by companies that are subject to French corporate income tax...\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   1%|          | 60/7952 [15:44<54:22:32, 24.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   1%|          | 70/7952 [18:59<42:59:16, 19.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   1%|          | 80/7952 [22:28<44:07:55, 20.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   1%|          | 90/7952 [25:00<43:21:54, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   1%|▏         | 100/7952 [28:37<50:15:56, 23.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   1%|▏         | 110/7952 [30:42<27:01:24, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   2%|▏         | 120/7952 [34:07<37:04:54, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   2%|▏         | 130/7952 [37:32<66:15:28, 30.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   2%|▏         | 140/7952 [41:02<47:12:42, 21.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   2%|▏         | 150/7952 [44:09<47:58:20, 22.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   2%|▏         | 159/7952 [46:27<35:15:52, 16.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Error encountered. Response was:\n",
      "{\n",
      "  \"Relevance\": \"Very High\",\n",
      "  \"Evidence\": \"The entire text\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   2%|▏         | 160/7952 [47:31<66:03:16, 30.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   2%|▏         | 170/7952 [51:19<51:17:12, 23.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   2%|▏         | 180/7952 [54:32<39:24:57, 18.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   2%|▏         | 190/7952 [56:44<25:34:20, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   3%|▎         | 200/7952 [1:00:07<47:16:57, 21.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   3%|▎         | 210/7952 [1:03:55<44:22:38, 20.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   3%|▎         | 220/7952 [1:06:23<40:35:39, 18.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   3%|▎         | 230/7952 [1:09:24<38:45:41, 18.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   3%|▎         | 240/7952 [1:12:27<40:15:24, 18.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   3%|▎         | 250/7952 [1:16:20<53:05:53, 24.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   3%|▎         | 260/7952 [1:19:24<45:35:57, 21.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   3%|▎         | 270/7952 [1:22:53<39:45:00, 18.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   4%|▎         | 280/7952 [1:25:01<28:53:35, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   4%|▎         | 290/7952 [1:28:49<44:18:04, 20.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   4%|▍         | 300/7952 [1:32:03<36:58:22, 17.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   4%|▍         | 310/7952 [1:35:55<37:47:29, 17.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   4%|▍         | 320/7952 [1:38:16<30:09:45, 14.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   4%|▍         | 330/7952 [1:41:53<36:51:24, 17.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   4%|▍         | 340/7952 [1:46:34<67:19:01, 31.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 340\n",
      "Parsing Error encountered. Response was:\n",
      "{\"Relevance\": \"Very Highly Relevant\", \"Evidence\": \"The phrases and sentences explaining the limitations on the validity and enforceability of the Note Guarantees and Security Interests under Italian law.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   4%|▍         | 350/7952 [1:50:07<34:36:22, 16.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   5%|▍         | 360/7952 [1:54:05<55:07:10, 26.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   5%|▍         | 370/7952 [1:57:20<35:12:23, 16.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   5%|▍         | 380/7952 [2:00:14<29:50:01, 14.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   5%|▍         | 390/7952 [2:03:19<42:42:59, 20.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   5%|▌         | 400/7952 [2:07:12<43:40:11, 20.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   5%|▌         | 410/7952 [2:10:25<43:26:15, 20.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   5%|▌         | 420/7952 [2:13:38<39:36:02, 18.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   5%|▌         | 430/7952 [2:16:24<36:47:48, 17.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   6%|▌         | 440/7952 [2:20:43<47:33:36, 22.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   6%|▌         | 450/7952 [2:23:46<36:10:33, 17.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   6%|▌         | 460/7952 [2:27:26<48:22:10, 23.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   6%|▌         | 470/7952 [2:31:20<45:53:50, 22.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   6%|▌         | 480/7952 [2:35:10<60:49:09, 29.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   6%|▌         | 490/7952 [2:38:57<50:27:21, 24.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   6%|▋         | 500/7952 [2:42:00<40:25:55, 19.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   6%|▋         | 510/7952 [2:44:53<30:15:33, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   7%|▋         | 520/7952 [2:46:38<18:38:50,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   7%|▋         | 530/7952 [2:48:10<21:06:21, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   7%|▋         | 540/7952 [2:50:18<29:42:10, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   7%|▋         | 550/7952 [2:54:12<46:07:41, 22.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   7%|▋         | 560/7952 [2:56:38<27:36:20, 13.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   7%|▋         | 570/7952 [3:00:27<41:11:25, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   7%|▋         | 580/7952 [3:03:07<35:00:58, 17.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   7%|▋         | 590/7952 [3:06:49<43:01:01, 21.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   8%|▊         | 600/7952 [3:10:21<46:31:22, 22.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   8%|▊         | 610/7952 [3:13:37<27:00:29, 13.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   8%|▊         | 620/7952 [3:16:10<33:53:39, 16.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   8%|▊         | 630/7952 [3:18:19<23:22:31, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   8%|▊         | 640/7952 [3:21:29<37:33:30, 18.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   8%|▊         | 650/7952 [3:23:40<18:15:23,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   8%|▊         | 659/7952 [3:26:25<45:33:15, 22.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing Error encountered. Response was:\n",
      "{\n",
      "  \"Relevance\": \"Very Relevant\",\n",
      "  \"Evidence\": \"Financial income increased by €1.0 million, or 81.6%, to €2.2 million for the year ended December 31, 2019 as compared to €1.2 million for the year ended December 31, 2018...\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   8%|▊         | 660/7952 [3:27:28<70:05:15, 34.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   8%|▊         | 670/7952 [3:29:49<32:25:33, 16.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   9%|▊         | 680/7952 [3:31:37<19:39:30,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   9%|▊         | 690/7952 [3:33:17<19:02:06,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   9%|▉         | 700/7952 [3:34:56<20:58:18, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   9%|▉         | 710/7952 [3:36:48<23:51:44, 11.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   9%|▉         | 720/7952 [3:40:05<37:20:16, 18.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   9%|▉         | 730/7952 [3:44:08<48:54:33, 24.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   9%|▉         | 740/7952 [3:48:48<43:11:38, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That was 10 more. Currently: 740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   9%|▉         | 747/7952 [3:51:21<40:11:43, 20.08s/it]"
     ]
    }
   ],
   "source": [
    "# Iterate over each row in the DataFrame with a progress bar\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Rows\"):\n",
    "    for question_dict in all_question_dicts:\n",
    "        for column_name, question in question_dict.items():\n",
    "            # Check if the answer column is already filled\n",
    "            if pd.notnull(df.at[index, column_name]) and df.at[index, column_name] != \"\":\n",
    "                # Skip processing this row for this question\n",
    "                continue\n",
    "            combined_answer = analyze_prospectus_row_single_question(row, question)\n",
    "            df.at[index, column_name] = combined_answer\n",
    "\n",
    "    # Save progress every 50 rows (adjusted from 35 to match the comment)\n",
    "    if (index + 1) % 2 == 0:\n",
    "        df.to_csv(processed_file_path, index=False)\n",
    "        #print(f\"Progress saved at row {index + 1}\")\n",
    "        if (index + 1) % 10 == 0:\n",
    "            print(f\"That was 10 more. Currently: {index + 1}\")\n",
    "\n",
    "\n",
    "# Save the final DataFrame after processing all rows\n",
    "df.to_csv(processed_file_path, index=False)\n",
    "print(\"All rows have been processed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mester_nlp_mini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
