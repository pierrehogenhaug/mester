{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this Notebook we extract the remaining SubScore Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code to extract unique score combinations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_with_fundamental_score = pd.read_pickle('./rms_with_fundamental_score.pkl')\n",
    "rms_with_fundamental_score.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_score_combinations = rms_with_fundamental_score[['CategoryGroup', 'Category', 'TaggedCharacteristics']].drop_duplicates()\n",
    "# Replace all types of newlines and excessive whitespace in TaggedCharacteristics\n",
    "unique_score_combinations['TaggedCharacteristics'] = unique_score_combinations['TaggedCharacteristics'].str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "\n",
    "# Function to expand TaggedCharacteristics if it's a JSON string with multiple items\n",
    "def expand_tagged_characteristics(row):\n",
    "    try:\n",
    "        characteristics = json.loads(row['TaggedCharacteristics'])\n",
    "        if isinstance(characteristics, list):\n",
    "            # Replace newlines within each CharacteristicText\n",
    "            return pd.DataFrame([{\n",
    "                'CategoryGroup': row['CategoryGroup'],\n",
    "                'Category': row['Category'],\n",
    "                'TaggedCharacteristics': char['CharacteristicText'].replace('\\r', ' ').replace('\\n', ' '),\n",
    "                'CharacteristicInfluence': char.get('CharacteristicInfluence', None)  # Handle missing keys\n",
    "            } for char in characteristics])\n",
    "        else:\n",
    "            # If it's a single item or not a list, replace newlines if it's a string\n",
    "            if isinstance(characteristics, str):\n",
    "                characteristics = characteristics.replace('\\r', ' ').replace('\\n', ' ')\n",
    "            return pd.DataFrame([{\n",
    "                'CategoryGroup': row['CategoryGroup'],\n",
    "                'Category': row['Category'],\n",
    "                'TaggedCharacteristics': characteristics,\n",
    "                'CharacteristicInfluence': row.get('CharacteristicInfluence', None)\n",
    "            }])\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        # If parsing fails, replace newlines in the original TaggedCharacteristics\n",
    "        cleaned_text = row['TaggedCharacteristics'].replace('\\r', ' ').replace('\\n', ' ')\n",
    "        return pd.DataFrame([{\n",
    "            'CategoryGroup': row['CategoryGroup'],\n",
    "            'Category': row['Category'],\n",
    "            'TaggedCharacteristics': cleaned_text,\n",
    "            'CharacteristicInfluence': row.get('CharacteristicInfluence', None)\n",
    "        }])\n",
    "\n",
    "# Applying the function to each row and combining results\n",
    "expanded_unique_score_combinations = pd.concat(\n",
    "    unique_score_combinations.apply(expand_tagged_characteristics, axis=1).to_list(),\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Sort, drop duplicates, and save to CSV\n",
    "unique_score_combinations = expanded_unique_score_combinations.sort_values(by=['CategoryGroup', 'Category', 'CharacteristicInfluence']).drop_duplicates()\n",
    "unique_score_combinations.to_csv('unique_score_combinations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the questions and instantiating the LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the questions corresponding to each column\n",
    "questions_market_dynamics = {\n",
    "    \"Market Dynamics - a\": \"Does the text mention that the company is exposed to risks associated with cyclical products?\",\n",
    "    \"Market Dynamics - b\": \"Does the text mention risks related to demographic or structural trends affecting the market?\",\n",
    "    \"Market Dynamics - c\": \"Does the text mention risks due to seasonal volatility in the industry?\"\n",
    "}\n",
    "questions_intra_industry_competition = {\n",
    "    \"Intra-Industry Competition - a\": \"Does the text mention that market pricing for the company's products or services is irrational or not based on fundamental factors?\",\n",
    "    \"Intra-Industry Competition - b\": \"Does the text mention that the market is highly fragmented with no clear leader or that there is only one dominant leader?\",\n",
    "    \"Intra-Industry Competition - c\": \"Does the text mention low barriers to entry in the industry, making it easy for new competitors to enter the market?\"\n",
    "}\n",
    "questions_regulatory_framework = {\n",
    "    \"Regulatory Framework - a\": \"Does the text mention that the industry is subject to a high degree of regulatory scrutiny?\",\n",
    "    \"Regulatory Framework - b\": \"Does the text mention a high dependency on regulation or being a beneficiary from regulation in an unstable regulatory environment?\"\n",
    "}\n",
    "questions_technology_risk = {\n",
    "    \"Technology Risk - a\": \"Does the text mention that the industry is susceptible to rapid technological advances or innovations?\",\n",
    "    \"Technology Risk - b\": \"Does the text mention that the company is perceived as a disruptor or is threatened by emerging technological changes?\"\n",
    "}\n",
    "\n",
    "all_question_dicts = [\n",
    "    questions_market_dynamics,\n",
    "    questions_intra_industry_competition,\n",
    "    questions_regulatory_framework,\n",
    "    questions_technology_risk\n",
    "]\n",
    "\n",
    "# Original questions\n",
    "questions_market_dynamics_original = {\n",
    "    \"Market Dynamics - a\": \"Exposure to cyclical products\",\n",
    "    \"Market Dynamics - b\": \"Impact of demographic and structural trends\",\n",
    "    \"Market Dynamics - c\": \"Seasonal industry volatility\"\n",
    "}\n",
    "questions_intra_industry_competition_original = {\n",
    "    \"Intra-Industry Competition - a\": \"Market pricing has not shown to be rational\",\n",
    "    \"Intra-Industry Competition - b\": \"Highly fragmented market with no clear leader or only one leader\",\n",
    "    \"Intra-Industry Competition - c\": \"Low barriers to entry\"\n",
    "}\n",
    "questions_regulatory_framework_original = {\n",
    "    \"Regulatory Framework - a\": \"Industry has high degree of regulatory scrutiny\",\n",
    "    \"Regulatory Framework - b\": \"High dependency on regulation or is a beneficiary from regulation in an unstable regulatory environment\"\n",
    "}\n",
    "questions_technology_risk_original = {\n",
    "    \"Technology Risk - a\": \"Industry susceptibility to technological advances\",\n",
    "    \"Technology Risk - b\": \"Company viewed as a disruptee/threatened by technological change\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prospectus ID</th>\n",
       "      <th>Original Filename</th>\n",
       "      <th>Section ID</th>\n",
       "      <th>Section Title</th>\n",
       "      <th>Subsection ID</th>\n",
       "      <th>Subsection Title</th>\n",
       "      <th>Subsubsection ID</th>\n",
       "      <th>Subsubsection Title</th>\n",
       "      <th>Subsubsection Text</th>\n",
       "      <th>Market Dynamics - a</th>\n",
       "      <th>Market Dynamics - b</th>\n",
       "      <th>Market Dynamics - c</th>\n",
       "      <th>Parsing Error</th>\n",
       "      <th>Intra-Industry Competition - a</th>\n",
       "      <th>Intra-Industry Competition - b</th>\n",
       "      <th>Intra-Industry Competition - c</th>\n",
       "      <th>Regulatory Framework - a</th>\n",
       "      <th>Regulatory Framework - b</th>\n",
       "      <th>Technology Risk - a</th>\n",
       "      <th>Technology Risk - b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>235</td>\n",
       "      <td>Final Offerings 2020.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>RISK FACTORS</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_An investment in the Notes involves a high de...</td>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>Highly Relevant: the risks described below</td>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>Highly Relevant: Subsubsection Title: ... and ...</td>\n",
       "      <td>Highly Relevant</td>\n",
       "      <td>Not Relevant</td>\n",
       "      <td>Not Relevant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Final Offerings 2020.pdf</td>\n",
       "      <td>1</td>\n",
       "      <td>RISK FACTORS</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Risks Relating to the Group’s Business, Techno...</td>\n",
       "      <td>1.1.1</td>\n",
       "      <td>The Group faces significant competition in eac...</td>\n",
       "      <td>The French telecommunications market is a matu...</td>\n",
       "      <td>Highly Relevant: Various evidence throughout t...</td>\n",
       "      <td>Highly Relevant</td>\n",
       "      <td>Highly Relevant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Highly Relevant</td>\n",
       "      <td>Highly Relevant: ...the Group also competes wi...</td>\n",
       "      <td>Highly Relevant: The exact phrases or sentence...</td>\n",
       "      <td>Highly Relevant: Several evidence are presente...</td>\n",
       "      <td>Highly Relevant</td>\n",
       "      <td>Highly Relevant: This is a highly relevant ans...</td>\n",
       "      <td>Highly Relevant: The Group also faces competit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Prospectus ID         Original Filename  Section ID Section Title  \\\n",
       "0           235  Final Offerings 2020.pdf           1  RISK FACTORS   \n",
       "1            16  Final Offerings 2020.pdf           1  RISK FACTORS   \n",
       "\n",
       "   Subsection ID                                   Subsection Title  \\\n",
       "0            1.1                                                NaN   \n",
       "1            1.1  Risks Relating to the Group’s Business, Techno...   \n",
       "\n",
       "  Subsubsection ID                                Subsubsection Title  \\\n",
       "0            1.1.1                                                NaN   \n",
       "1            1.1.1  The Group faces significant competition in eac...   \n",
       "\n",
       "                                  Subsubsection Text  \\\n",
       "0  _An investment in the Notes involves a high de...   \n",
       "1  The French telecommunications market is a matu...   \n",
       "\n",
       "                                 Market Dynamics - a  \\\n",
       "0                                       Not Relevant   \n",
       "1  Highly Relevant: Various evidence throughout t...   \n",
       "\n",
       "                          Market Dynamics - b Market Dynamics - c  \\\n",
       "0  Highly Relevant: the risks described below        Not Relevant   \n",
       "1                             Highly Relevant     Highly Relevant   \n",
       "\n",
       "   Parsing Error Intra-Industry Competition - a  \\\n",
       "0            NaN                   Not Relevant   \n",
       "1            NaN                Highly Relevant   \n",
       "\n",
       "                      Intra-Industry Competition - b  \\\n",
       "0                                       Not Relevant   \n",
       "1  Highly Relevant: ...the Group also competes wi...   \n",
       "\n",
       "                      Intra-Industry Competition - c  \\\n",
       "0                                       Not Relevant   \n",
       "1  Highly Relevant: The exact phrases or sentence...   \n",
       "\n",
       "                            Regulatory Framework - a Regulatory Framework - b  \\\n",
       "0  Highly Relevant: Subsubsection Title: ... and ...          Highly Relevant   \n",
       "1  Highly Relevant: Several evidence are presente...          Highly Relevant   \n",
       "\n",
       "                                 Technology Risk - a  \\\n",
       "0                                       Not Relevant   \n",
       "1  Highly Relevant: This is a highly relevant ans...   \n",
       "\n",
       "                                 Technology Risk - b  \n",
       "0                                       Not Relevant  \n",
       "1  Highly Relevant: The Group also faces competit...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the language model\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Check if the processed file exists; if not, process the raw data\n",
    "processed_file_path = '../data/prospectuses_data_processed.csv'\n",
    "raw_file_path = '../data/prospectuses_data.csv'\n",
    "\n",
    "# Check if processed file exists\n",
    "if os.path.exists(processed_file_path):\n",
    "    df = pd.read_csv(processed_file_path)\n",
    "else:\n",
    "    print(\"Processed file not found. Processing raw data...\")\n",
    "    df = pd.read_csv(raw_file_path)\n",
    "    # Filter out rows that have \"failed parsing\" in the Section ID column\n",
    "    df = df[df['Section ID'] != \"failed parsing\"]\n",
    "\n",
    "# Ensure the relevance and evidence columns are created with a compatible data type\n",
    "for question_dict in all_question_dicts:\n",
    "    # Iterate through each question key in the current dictionary\n",
    "    for column_name in question_dict.keys():\n",
    "        if column_name in df.columns:\n",
    "            df[column_name] = df[column_name].astype('string')\n",
    "        else:\n",
    "            df[column_name] = \"\"\n",
    "\n",
    "df.head(2)\n",
    "# print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields(response):\n",
    "    # Remove any newlines and extra spaces\n",
    "    response = ' '.join(response.strip().split())\n",
    "\n",
    "    # Extract the Relevance field\n",
    "    relevance_match = re.search(r'\"Relevance\"\\s*:\\s*\"([^\"]+)\"', response)\n",
    "    if relevance_match:\n",
    "        relevance = relevance_match.group(1).strip()\n",
    "    else:\n",
    "        relevance = \"Parsing Error\"\n",
    "\n",
    "    # Extract the Evidence field(s)\n",
    "    evidence_match = re.search(r'\"Evidence\"\\s*:\\s*(.+?)(?:,?\\s*\"[^\"]+\"\\s*:|\\s*}$)', response)\n",
    "    if evidence_match:\n",
    "        evidence_str = evidence_match.group(1).strip()\n",
    "        # Remove any trailing commas or braces\n",
    "        evidence_str = evidence_str.rstrip(', }')\n",
    "        # Split the evidence_str into individual evidence items\n",
    "        # Evidence items are strings enclosed in double quotes\n",
    "        evidence_items = re.findall(r'\"([^\"]+)\"', evidence_str)\n",
    "        evidence = evidence_items\n",
    "    else:\n",
    "        evidence = []\n",
    "\n",
    "    return relevance, evidence\n",
    "\n",
    "\n",
    "def analyze_prospectus_row_single_question(row, question):\n",
    "    # System and user prompts\n",
    "    system_prompt = \"You are an expert in analyzing bond prospectuses and identifying specific risk factors.\"\n",
    "\n",
    "    # Format the user prompt using the row's data\n",
    "    prompt = f\"\"\"\n",
    "{system_prompt}\n",
    "\n",
    "For the following question and text, judge whether the text is \"Highly Relevant\", \"Somewhat Relevant\", or \"Not Relevant\".\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Text:\n",
    "Subsubsection Title: {row['Subsubsection Title']}\n",
    "Subsubsection Text: {row['Subsubsection Text']}\n",
    "\n",
    "\n",
    "Please provide your answer in the following JSON format:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"Highly Relevant\", \"Somewhat Relevant\", or \"Not Relevant\",\n",
    "  \"Evidence\": \"The exact phrases or sentences from the document that support your assessment; otherwise, leave blank.\"\n",
    "}}\n",
    "\n",
    "Note: Only provide the JSON response without any additional text.\n",
    "\"\"\"\n",
    "    # Run the prompt through the model\n",
    "    response = llm.invoke(input=prompt)\n",
    "\n",
    "    # Parse the response\n",
    "    try:\n",
    "        # Extract the Relevance and Evidence fields\n",
    "        relevance, evidence_list = extract_fields(response)\n",
    "        # Join multiple evidence items into a single string\n",
    "        evidence = '; '.join(evidence_list)\n",
    "    except Exception as e:\n",
    "        relevance = \"Parsing Error\"\n",
    "        evidence = \"\"\n",
    "\n",
    "    # Combine relevance and evidence\n",
    "    if relevance in [\"Highly Relevant\", \"Somewhat Relevant\"] and evidence:\n",
    "        combined_answer = f\"{relevance}: {evidence}\"\n",
    "    elif relevance in [\"Highly Relevant\", \"Somewhat Relevant\"]:\n",
    "        combined_answer = relevance\n",
    "    elif relevance == \"Not Relevant\":\n",
    "        combined_answer = \"Not Relevant\"\n",
    "    else:\n",
    "        combined_answer = \"Parsing Error\"\n",
    "\n",
    "    # For debugging\n",
    "    if combined_answer == \"Parsing Error\":\n",
    "        print(\"Parsing Error encountered. Response was:\")\n",
    "        print(response)\n",
    "\n",
    "    return combined_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run the LLM Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:   0%|          | 0/7952 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  92%|█████████▏| 7329/7952 [03:30<1:06:10,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  92%|█████████▏| 7339/7952 [06:38<3:06:12, 18.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  92%|█████████▏| 7349/7952 [10:01<3:45:28, 22.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  93%|█████████▎| 7359/7952 [11:55<2:06:28, 12.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  93%|█████████▎| 7369/7952 [14:38<2:58:52, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  93%|█████████▎| 7379/7952 [18:30<3:08:27, 19.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  93%|█████████▎| 7389/7952 [21:13<2:50:37, 18.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  93%|█████████▎| 7399/7952 [23:57<2:25:32, 15.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  93%|█████████▎| 7409/7952 [26:27<2:39:26, 17.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  93%|█████████▎| 7419/7952 [29:50<3:10:53, 21.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  93%|█████████▎| 7429/7952 [33:25<3:55:50, 27.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  94%|█████████▎| 7439/7952 [35:33<2:02:23, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  94%|█████████▎| 7449/7952 [37:58<2:14:05, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  94%|█████████▍| 7459/7952 [40:16<1:44:55, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  94%|█████████▍| 7469/7952 [42:49<2:13:54, 16.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  94%|█████████▍| 7479/7952 [45:09<1:50:58, 14.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  94%|█████████▍| 7489/7952 [47:58<1:47:52, 13.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  94%|█████████▍| 7499/7952 [51:07<3:02:12, 24.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  94%|█████████▍| 7509/7952 [54:01<2:14:58, 18.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  95%|█████████▍| 7519/7952 [56:32<2:14:34, 18.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  95%|█████████▍| 7529/7952 [59:11<1:45:54, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  95%|█████████▍| 7539/7952 [1:01:29<1:32:24, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  95%|█████████▍| 7549/7952 [1:03:30<1:30:55, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  95%|█████████▌| 7559/7952 [1:05:55<1:29:06, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  95%|█████████▌| 7569/7952 [1:08:42<1:30:23, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  95%|█████████▌| 7579/7952 [1:11:08<1:25:01, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  95%|█████████▌| 7589/7952 [1:14:11<2:14:02, 22.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  96%|█████████▌| 7599/7952 [1:19:01<2:26:33, 24.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  96%|█████████▌| 7609/7952 [1:22:36<2:16:50, 23.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  96%|█████████▌| 7619/7952 [1:26:29<2:24:32, 26.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  96%|█████████▌| 7629/7952 [1:30:21<1:58:34, 22.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  96%|█████████▌| 7639/7952 [1:33:44<1:28:30, 16.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  96%|█████████▌| 7649/7952 [1:38:37<2:26:51, 29.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  96%|█████████▋| 7659/7952 [1:41:30<1:41:55, 20.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  96%|█████████▋| 7669/7952 [1:45:49<1:28:53, 18.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  97%|█████████▋| 7679/7952 [1:49:07<1:24:18, 18.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  97%|█████████▋| 7689/7952 [1:52:56<1:11:11, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  97%|█████████▋| 7699/7952 [1:56:45<2:05:14, 29.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  97%|█████████▋| 7709/7952 [2:01:19<1:46:53, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  97%|█████████▋| 7719/7952 [2:06:02<2:01:47, 31.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  97%|█████████▋| 7729/7952 [2:10:04<1:45:50, 28.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  97%|█████████▋| 7739/7952 [2:13:32<1:31:48, 25.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  97%|█████████▋| 7749/7952 [2:16:30<56:11, 16.61s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  98%|█████████▊| 7759/7952 [2:19:32<42:47, 13.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  98%|█████████▊| 7769/7952 [2:23:20<1:13:06, 23.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  98%|█████████▊| 7779/7952 [2:26:42<53:26, 18.53s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  98%|█████████▊| 7789/7952 [2:29:38<45:47, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  98%|█████████▊| 7799/7952 [2:32:28<49:41, 19.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  98%|█████████▊| 7809/7952 [2:34:58<38:20, 16.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  98%|█████████▊| 7819/7952 [2:37:53<42:21, 19.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  98%|█████████▊| 7829/7952 [2:41:17<56:23, 27.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  99%|█████████▊| 7839/7952 [2:43:56<37:10, 19.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  99%|█████████▊| 7849/7952 [2:46:54<26:48, 15.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  99%|█████████▉| 7859/7952 [2:49:52<32:33, 21.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  99%|█████████▉| 7869/7952 [2:53:47<27:47, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  99%|█████████▉| 7879/7952 [2:56:42<20:06, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  99%|█████████▉| 7889/7952 [2:59:25<15:29, 14.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  99%|█████████▉| 7899/7952 [3:02:21<15:00, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  99%|█████████▉| 7909/7952 [3:06:27<15:48, 22.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|█████████▉| 7919/7952 [3:10:40<12:33, 22.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|█████████▉| 7929/7952 [3:13:32<07:20, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|█████████▉| 7939/7952 [3:16:06<02:54, 13.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|█████████▉| 7949/7952 [3:18:27<00:39, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 new rows. Pausing for 30 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 7952/7952 [3:19:09<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows have been processed and saved.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Initialize counter for new rows processed\n",
    "new_rows_processed = 0\n",
    "\n",
    "# Iterate over each row in the DataFrame with a progress bar\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing Rows\"):\n",
    "    row_processed = False  # Flag to check if we processed any new data in this row\n",
    "\n",
    "    for question_dict in all_question_dicts:\n",
    "        for column_name, question in question_dict.items():\n",
    "            # Check if the answer column is already filled\n",
    "            if pd.notnull(df.at[index, column_name]) and df.at[index, column_name] != \"\":\n",
    "                # Skip processing this row for this question\n",
    "                continue\n",
    "            combined_answer = analyze_prospectus_row_single_question(row, question)\n",
    "            df.at[index, column_name] = combined_answer\n",
    "            row_processed = True  # We processed new data in this row\n",
    "\n",
    "    if row_processed:\n",
    "        new_rows_processed += 1\n",
    "\n",
    "    # Save progress every 50 rows\n",
    "    if (index + 1) % 50 == 0:\n",
    "        df.to_csv(processed_file_path, index=False)\n",
    "        # print(f\"Progress saved at row {index + 1}\")\n",
    "\n",
    "    # After processing 10 new rows, sleep for 30 seconds\n",
    "    if new_rows_processed >= 10:\n",
    "        df.to_csv(processed_file_path, index=False)  # Save before sleeping\n",
    "        print(f\"Processed 10 new rows. Pausing for 30 seconds.\")\n",
    "        # time.sleep(30)\n",
    "        new_rows_processed = 0  # Reset counter\n",
    "\n",
    "# Save the final DataFrame after processing all rows\n",
    "df.to_csv(processed_file_path, index=False)\n",
    "print(\"All rows have been processed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mester_nlp_mini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
