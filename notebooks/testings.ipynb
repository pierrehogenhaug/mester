{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from capfourpy.authentication import get_access_token_interactive, get_azure_db_token_api\n",
    "from capfourpy.sharepoint import SharePoint\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import platform\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subclassing**: CustomSharePoint inherits from SharePoint, so it will have all the same methods and attributes.\n",
    "\n",
    "**Method Override**: By defining fetch_list_data within CustomSharePoint, it overrides the fetch_list_data method of the base SharePoint class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSharePoint(SharePoint):\n",
    "    \"\"\"\n",
    "    Subclass that inherits from capfourpy SharePoint\n",
    "    \"\"\"\n",
    "\n",
    "    # Class variable to store the token\n",
    "    idp_token = None\n",
    "\n",
    "    def _generate_token(self, token: str = \"missing idp token\"):\n",
    "        \"\"\"\n",
    "        Retrieves an authentication token using different methods based on the environment,\n",
    "        and caches it as a class-level variable to avoid repeated authentications.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        token (str, optional): Default token value, used when deployed. Defaults to \"missing idp token\".\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str: Authentication token for accessing SharePoint API.\n",
    "        \"\"\"\n",
    "        # Check if the token is already cached\n",
    "        if CustomSharePoint.idp_token is not None:\n",
    "            return CustomSharePoint.idp_token\n",
    "\n",
    "        # Generate the token - different methods for hosted and local\n",
    "        if platform.system() == \"Linux\":\n",
    "            try:\n",
    "                token = get_azure_db_token_api(scope=self.Scope)\n",
    "            except:\n",
    "                token = token  # Should always have a value when deployed, otherwise it will fail\n",
    "        else:\n",
    "            print(\"get_access_token_interactive\")\n",
    "            token = get_access_token_interactive(self.Client_Id, self.Tenant_Id, self.Scope)\n",
    "\n",
    "        # Cache the token at the class level\n",
    "        CustomSharePoint.idp_token = token\n",
    "        return token\n",
    "\n",
    "\n",
    "    def fetch_list_data(self, ListId: str = None, SiteUrl: str = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves all data from a specified SharePoint list and converts it to a DataFrame.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ListId (str, optional): The unique identifier of the SharePoint list to retrieve.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame: DataFrame containing all items from the specified SharePoint list.\n",
    "        \"\"\"\n",
    "        large_list = self.ctx.web.lists.get_by_id(list_id=ListId)\n",
    "\n",
    "        # items = large_list.items.get().execute_query()\n",
    "        items = large_list.items.get_all().execute_query()\n",
    "        # items = large_list.items.get_all().execute_query(500) # adding some number makes it run faster dunno why\n",
    "        data = [item.properties for item in items]\n",
    "\n",
    "        return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "    def get_files_metadata(self, folder_url: str):\n",
    "        \"\"\"\n",
    "        Retrieves files in the specified SharePoint folder along with their metadata.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        folder_url : str\n",
    "            The relative URL of the target SharePoint folder.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List\n",
    "            List of files with metadata in the specified folder.\n",
    "        \"\"\"\n",
    "        folder = self.ctx.web.get_folder_by_server_relative_url(folder_url)\n",
    "        # Expand to include ListItemAllFields to access metadata\n",
    "        files_metadata = folder.files.expand([\"ListItemAllFields\"]).get().execute_query()\n",
    "        return files_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_access_token_interactive\n",
      "No accounts found in cache.\n",
      "No cached token found or expired. Initiating interactive authentication...\n"
     ]
    }
   ],
   "source": [
    "ListId = \"6ba7678f-2b65-4ad4-8759-21b68035c8c8\"\n",
    "SiteUrl = \"https://c4.sharepoint.com/sites/IMP\"\n",
    "\n",
    "sp = CustomSharePoint(site_url=SiteUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3865, 27)\n",
      "Index(['FileSystemObjectType', 'Id', 'ServerRedirectedEmbedUri',\n",
      "       'ServerRedirectedEmbedUrl', 'ID', 'ContentTypeId', 'Title', 'Modified',\n",
      "       'Created', 'AuthorId', 'EditorId', 'OData__UIVersionString',\n",
      "       'Attachments', 'GUID', 'ComplianceAssetId', 'EB_Created', 'EB_ID',\n",
      "       'EB_ListID', 'EB_SiteID', 'EB_SiteTitle', 'EB_SPWebUrl', 'EB_Url',\n",
      "       'FlowLog', 'EB_UniqueID', 'EB_Author', 'OData__ColorTag',\n",
      "       'EB_NoteType'],\n",
      "      dtype='object')\n",
      "[np.int64(0) np.int64(1) None '' np.int64(1)\n",
      " '0x0100F85F83B9B7B2164B971E241601880D090012394ABE830548438DEE171159507E12'\n",
      " 'Faurecia FY 2020' '2021-12-01T12:22:22Z' '2021-12-01T12:22:22Z'\n",
      " np.int64(1073741822) np.int64(1073741822) '1.0' np.False_\n",
      " '6aa973a0-d18c-4c15-9b4f-01f187e1f20d' None '2021-07-21T04:57:14Z'\n",
      " np.int64(12) 'cc3155c9-9c23-4de3-a701-624e2d25feab'\n",
      " 'b689d508-5290-4291-aa89-61470e5c2413' 'Faurecia'\n",
      " 'https://c4.sharepoint.com/sites/Faurecia73'\n",
      " 'https://c4.sharepoint.com/sites/Faurecia73/SitePages/Faurecia-FY-2020(1).aspx'\n",
      " None 'a2f533c1-1683-48b4-9d26-a712c114d2e3' 'Aske Taastr√∏m' None None]\n",
      "https://c4.sharepoint.com/sites/Faurecia73\n",
      "https://c4.sharepoint.com/sites/Faurecia73/SitePages/Faurecia-FY-2020(1).aspx\n"
     ]
    }
   ],
   "source": [
    "sp_data = sp.fetch_list_data(SiteUrl=SiteUrl, ListId=ListId)\n",
    "print(sp_data.shape)\n",
    "print(sp_data.columns)\n",
    "print(sp_data.iloc[0].values)\n",
    "print(sp_data.EB_SPWebUrl.values[0])\n",
    "print(sp_data.EB_Url.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store CustomSharePoint instances for each site URL to avoid redundant initializations\n",
    "sp_instances = {}\n",
    "\n",
    "\n",
    "def download_specific_files_for_row(row, desired_document_type, desired_document_subtype):\n",
    "    \"\"\"\n",
    "    Downloads files with specific metadata values from the '/Reorg/' document library for a given site.\n",
    "    Saves the files into the specified output_folder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : pd.Series\n",
    "        A row from the dataframe containing 'EB_SPWebUrl'.\n",
    "    desired_document_type : str\n",
    "        The desired value for the \"Document Type\" column.\n",
    "    desired_document_subtype : str\n",
    "        The desired value for the \"Document SubType\" column.\n",
    "    output_folder : str\n",
    "        The folder path where files will be saved.\n",
    "    \"\"\"\n",
    "    site_url = row['EB_SPWebUrl']\n",
    "    rms_id = row['RmsId']\n",
    "    if pd.isna(site_url):\n",
    "        return\n",
    "\n",
    "    # Use or create a CustomSharePoint instance for this site URL\n",
    "    if site_url not in sp_instances:\n",
    "        sp_instances[site_url] = CustomSharePoint(site_url=site_url)\n",
    "    sp = sp_instances[site_url]\n",
    "\n",
    "    # Construct the server-relative URL for the '/Reorg/' folder\n",
    "    parsed_url = urlparse(site_url)\n",
    "    server_relative_url = parsed_url.path.rstrip('/') + '/Reorg/'\n",
    "\n",
    "    # Initialize a flag to check if the folder has been created\n",
    "    folder_created = False\n",
    "    files_downloaded = False  # Flag to check if any files were downloaded\n",
    "\n",
    "    # Get files with metadata in the folder\n",
    "    try:\n",
    "        files = sp.get_files_metadata(server_relative_url)\n",
    "        for file in files:\n",
    "            list_item_properties = file.listItemAllFields.properties\n",
    "            document_type = list_item_properties.get(\"DocumentType\", None)\n",
    "            document_subtype = list_item_properties.get(\"DocumentSubType\", None)\n",
    "            \n",
    "            if document_type == desired_document_type and document_subtype == desired_document_subtype:\n",
    "                # Get the file name\n",
    "                file_name = file.name\n",
    "\n",
    "                # Define the output folder path\n",
    "                output_folder = os.path.join('../data/raw/sharepoint_reorg_files/', str(rms_id))\n",
    "\n",
    "                # Check if the file already exists\n",
    "                file_path = os.path.join(output_folder, file_name)\n",
    "                if not os.path.exists(file_path):\n",
    "                    # Create the folder if it hasn't been created yet\n",
    "                    if not folder_created:\n",
    "                        os.makedirs(output_folder, exist_ok=True)\n",
    "                        folder_created = True\n",
    "\n",
    "                    # Download the file\n",
    "                    file_url = file.serverRelativeUrl\n",
    "                    file_stream = sp.download_file(file_url)\n",
    "                    # Save the file into the specified output folder\n",
    "                    with open(file_path, 'wb') as f:\n",
    "                        f.write(file_stream.read())\n",
    "                    print(f\"Downloaded file {file_name} from {site_url} to {output_folder}\")\n",
    "                    files_downloaded = True\n",
    "                else:\n",
    "                    pass\n",
    "                    #print(f\"File {file_name} already exists in {output_folder}, skipping download.\")\n",
    "        if not files_downloaded:\n",
    "            print(f\"No new files to download for RmsId {rms_id} at {server_relative_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download files from {server_relative_url}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Connection\n",
    "- **fundamental_score**: `CfRms_prod` Fundamental Scores Data\n",
    "- **rms_issuer**: `CfRms_prod` Linking RmsId to SharePoint Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RmsId</th>\n",
       "      <th>ScoringDate</th>\n",
       "      <th>CategoryGroup</th>\n",
       "      <th>Category</th>\n",
       "      <th>Score</th>\n",
       "      <th>TaggedCharacteristics</th>\n",
       "      <th>CompanyName</th>\n",
       "      <th>Status</th>\n",
       "      <th>SharePointLink</th>\n",
       "      <th>SharePointLinkTruncated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194</td>\n",
       "      <td>2021-04-15</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Market Dynamics</td>\n",
       "      <td>2.0000000000</td>\n",
       "      <td>[{\"CharacteristicText\":\"Positive demographic, ...</td>\n",
       "      <td>Nexi</td>\n",
       "      <td>Active</td>\n",
       "      <td>https://c4.sharepoint.com/sites/194/</td>\n",
       "      <td>https://c4.sharepoint.com/sites/194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194</td>\n",
       "      <td>2021-04-15</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Intra-Industry Competition</td>\n",
       "      <td>2.0000000000</td>\n",
       "      <td>[{\"CharacteristicText\":\"Market share is consol...</td>\n",
       "      <td>Nexi</td>\n",
       "      <td>Active</td>\n",
       "      <td>https://c4.sharepoint.com/sites/194/</td>\n",
       "      <td>https://c4.sharepoint.com/sites/194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RmsId ScoringDate CategoryGroup                    Category         Score  \\\n",
       "0    194  2021-04-15      Industry             Market Dynamics  2.0000000000   \n",
       "1    194  2021-04-15      Industry  Intra-Industry Competition  2.0000000000   \n",
       "\n",
       "                               TaggedCharacteristics CompanyName  Status  \\\n",
       "0  [{\"CharacteristicText\":\"Positive demographic, ...        Nexi  Active   \n",
       "1  [{\"CharacteristicText\":\"Market share is consol...        Nexi  Active   \n",
       "\n",
       "                         SharePointLink              SharePointLinkTruncated  \n",
       "0  https://c4.sharepoint.com/sites/194/  https://c4.sharepoint.com/sites/194  \n",
       "1  https://c4.sharepoint.com/sites/194/  https://c4.sharepoint.com/sites/194  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from capfourpy.databases import Database\n",
    "#import pickle as pkl\n",
    "\n",
    "\n",
    "# To retrieve data from the Azure database:\n",
    "db = Database(database=\"CfRms_prod\", azure=True)\n",
    "sql_query_fundamental_score = \"\"\"\n",
    "WITH tbl1 AS(\n",
    "\tSELECT r.ScoringId,\n",
    "\t\t   r.RmsId,\n",
    "\t\t   t.TemplateName AS ScoringType,\n",
    "\t\t   r.ScoringDate,\n",
    "\t\t   cat.Grouping AS CategoryGroup,\n",
    "\t\t   cat.Name AS Category,\n",
    "\t\t   rc.Score,\n",
    "\t\t   rc.Text,\n",
    "\t\t   (\n",
    "\t\t\t   SELECT c.Description AS CharacteristicText,\n",
    "\t\t\t\t\t  c.Influence AS CharacteristicInfluence\n",
    "\t\t\t   FROM Scoring.ResultCharacteristic AS rca\n",
    "\t\t\t\t   LEFT JOIN Scoring.Characteristic AS c ON c.CategoryId = rca.CategoryId AND c.CharacteristicId = rca.CharacteristicId\n",
    "\t\t\t   WHERE rca.ScoringId = rc.ScoringId AND rca.CategoryId = rc.CategoryId\n",
    "\t\t\t   FOR JSON PATH\n",
    "\t\t   ) AS TaggedCharacteristics\n",
    "\tFROM Scoring.Result AS r\n",
    "\t\tINNER JOIN Scoring.Template AS t ON t.TemplateId = r.TemplateId\n",
    "\t\tINNER JOIN Scoring.ResultCategory AS rc ON rc.ScoringId = r.ScoringId\n",
    "\t\tINNER JOIN Scoring.Category AS cat ON cat.CategoryId = rc.CategoryId\n",
    "\tWHERE t.TemplateName = 'Corporate'\n",
    ")\n",
    "SELECT * FROM tbl1 WHERE TaggedCharacteristics IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "sql_query_rms_issuer = \"\"\"\n",
    "SELECT *\n",
    "FROM [CfRms_prod].[Core].[RmsIssuer]\n",
    "WHERE SharePointLink IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "# Define dataframes from sql queries\n",
    "fundamental_score = db.read_sql(sql_query_fundamental_score)\n",
    "rms_issuer = db.read_sql(sql_query_rms_issuer)\n",
    "\n",
    "# Keep only relevant columns\n",
    "columns_to_remove_fundamental_score = ['ScoringId', 'ScoringType', 'Text']\n",
    "columns_to_remove_rms_issuer = ['PrimaryAnalystId', 'SecondaryAnalystId', 'ResearchTeam',\n",
    "       'CompanyDescription', 'BondTicker',\n",
    "       'OperatingCountryIso', 'Industry', 'Sponsor', 'MajorityOwnership',\n",
    "       'MinorityOwnership', 'WhyInvested', 'CreditPositives',\n",
    "       'CreditNegatives', 'CreditView', 'BookType', \n",
    "       'UpdateUser', 'SharePointExcelModel', 'SharePointSiteName',\n",
    "       'SharePointProvisioningStatus', 'SubIndustry',\n",
    "       'SharePointProvisioningMessage'] # 'Status',\n",
    "\n",
    "fundamental_score = fundamental_score.drop(columns=columns_to_remove_fundamental_score)\n",
    "rms_issuer = rms_issuer.drop(columns=columns_to_remove_rms_issuer)\n",
    "\n",
    "# Get a DataFrame with only names that have Fundamental Score\n",
    "rms_with_fundamental_score = fundamental_score.merge(rms_issuer, on='RmsId', how='left')\n",
    "rms_with_fundamental_score[\"SharePointLinkTruncated\"] = rms_with_fundamental_score[\"SharePointLink\"].apply(lambda x: x[:-1] if str(x).endswith('/') else x)\n",
    "#rms_with_fundamental_score.to_pickle(\"./rms_with_fundamental_score.pkl\")\n",
    "rms_with_fundamental_score.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save subset of rms_with_fundamental_score df just to test it\n",
    "df = rms_with_fundamental_score.head(25)\n",
    "#df.to_pickle(\"./df_rms_with_fundamental_score.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Let's see how many SharePoint Sites we can link from our rms_with_fundamental_score to sp_data\n",
    "# unique_site_urls_sp_data = set(sp_data[\"EB_SPWebUrl\"])\n",
    "# unique_site_urls_rms_data = set(rms_with_fundamental_score[\"SharePointLinkTruncated\"])\n",
    "\n",
    "# count_unique_sp_data_site_urls = len(unique_site_urls_sp_data)\n",
    "# count_rms_site_urls = len(unique_site_urls_rms_data)\n",
    "# common_elements_count = len(unique_site_urls_sp_data.intersection(unique_site_urls_rms_data))\n",
    "\n",
    "# print(count_unique_sp_data_site_urls, count_rms_site_urls, common_elements_count)\n",
    "# unique_to_rms_site_urls = unique_site_urls_rms_data - unique_site_urls_sp_data\n",
    "# unique_to_rms_site_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pih\\AppData\\Local\\Temp\\ipykernel_18548\\2703281679.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sp_data_unique['EB_SPWebUrl_cleaned'] = sp_data_unique['EB_SPWebUrl'].astype(str).str.rstrip('/')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileSystemObjectType</th>\n",
       "      <th>Id</th>\n",
       "      <th>ServerRedirectedEmbedUri</th>\n",
       "      <th>ServerRedirectedEmbedUrl</th>\n",
       "      <th>ID</th>\n",
       "      <th>ContentTypeId</th>\n",
       "      <th>Title</th>\n",
       "      <th>Modified</th>\n",
       "      <th>Created</th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>...</th>\n",
       "      <th>EB_Url</th>\n",
       "      <th>FlowLog</th>\n",
       "      <th>EB_UniqueID</th>\n",
       "      <th>EB_Author</th>\n",
       "      <th>OData__ColorTag</th>\n",
       "      <th>EB_NoteType</th>\n",
       "      <th>EB_SPWebUrl_cleaned</th>\n",
       "      <th>SharePointLinkTruncated_cleaned</th>\n",
       "      <th>RmsId</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0x0100F85F83B9B7B2164B971E241601880D090012394A...</td>\n",
       "      <td>Faurecia FY 2020</td>\n",
       "      <td>2021-12-01T12:22:22Z</td>\n",
       "      <td>2021-12-01T12:22:22Z</td>\n",
       "      <td>1073741822</td>\n",
       "      <td>...</td>\n",
       "      <td>https://c4.sharepoint.com/sites/Faurecia73/Sit...</td>\n",
       "      <td>None</td>\n",
       "      <td>a2f533c1-1683-48b4-9d26-a712c114d2e3</td>\n",
       "      <td>Aske Taastr√∏m</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://c4.sharepoint.com/sites/Faurecia73</td>\n",
       "      <td>https://c4.sharepoint.com/sites/Faurecia73</td>\n",
       "      <td>127</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>0x0100F85F83B9B7B2164B971E241601880D090012394A...</td>\n",
       "      <td>Techem - 3Q21 Results - Positive</td>\n",
       "      <td>2021-12-01T12:22:35Z</td>\n",
       "      <td>2021-12-01T12:22:35Z</td>\n",
       "      <td>1073741822</td>\n",
       "      <td>...</td>\n",
       "      <td>https://c4.sharepoint.com/sites/4692/SitePages...</td>\n",
       "      <td>None</td>\n",
       "      <td>4c6d3508-2663-4158-b37b-c1260b73f742</td>\n",
       "      <td>Andreas Dahl Jensen</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://c4.sharepoint.com/sites/4692</td>\n",
       "      <td>https://c4.sharepoint.com/sites/4692</td>\n",
       "      <td>287</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FileSystemObjectType  Id ServerRedirectedEmbedUri ServerRedirectedEmbedUrl  \\\n",
       "0                     0   1                     None                            \n",
       "7                     0   5                     None                            \n",
       "\n",
       "   ID                                      ContentTypeId  \\\n",
       "0   1  0x0100F85F83B9B7B2164B971E241601880D090012394A...   \n",
       "7   5  0x0100F85F83B9B7B2164B971E241601880D090012394A...   \n",
       "\n",
       "                              Title              Modified  \\\n",
       "0                  Faurecia FY 2020  2021-12-01T12:22:22Z   \n",
       "7  Techem - 3Q21 Results - Positive  2021-12-01T12:22:35Z   \n",
       "\n",
       "                Created    AuthorId  ...  \\\n",
       "0  2021-12-01T12:22:22Z  1073741822  ...   \n",
       "7  2021-12-01T12:22:35Z  1073741822  ...   \n",
       "\n",
       "                                              EB_Url FlowLog  \\\n",
       "0  https://c4.sharepoint.com/sites/Faurecia73/Sit...    None   \n",
       "7  https://c4.sharepoint.com/sites/4692/SitePages...    None   \n",
       "\n",
       "                            EB_UniqueID            EB_Author OData__ColorTag  \\\n",
       "0  a2f533c1-1683-48b4-9d26-a712c114d2e3        Aske Taastr√∏m            None   \n",
       "7  4c6d3508-2663-4158-b37b-c1260b73f742  Andreas Dahl Jensen            None   \n",
       "\n",
       "  EB_NoteType                         EB_SPWebUrl_cleaned  \\\n",
       "0        None  https://c4.sharepoint.com/sites/Faurecia73   \n",
       "7        None        https://c4.sharepoint.com/sites/4692   \n",
       "\n",
       "              SharePointLinkTruncated_cleaned RmsId  Status  \n",
       "0  https://c4.sharepoint.com/sites/Faurecia73   127  Active  \n",
       "7        https://c4.sharepoint.com/sites/4692   287  Active  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_data_unique = sp_data.drop_duplicates(subset='EB_SPWebUrl')\n",
    "# sp_data_unique_50 = sp_data_unique.head(50)\n",
    "\n",
    "# Clean and prepare URLs for matching\n",
    "sp_data_unique['EB_SPWebUrl_cleaned'] = sp_data_unique['EB_SPWebUrl'].astype(str).str.rstrip('/')\n",
    "rms_with_fundamental_score['SharePointLinkTruncated_cleaned'] = rms_with_fundamental_score['SharePointLinkTruncated'].astype(str).str.rstrip('/')\n",
    "\n",
    "# Merge dataframes on cleaned URLs\n",
    "merged_data = sp_data_unique.merge(\n",
    "    rms_with_fundamental_score[['SharePointLinkTruncated_cleaned', 'RmsId', 'Status']],\n",
    "    left_on='EB_SPWebUrl_cleaned',\n",
    "    right_on='SharePointLinkTruncated_cleaned',\n",
    "    how='left')\n",
    "\n",
    "# Cast RMS and drop rows with missing RmsId\n",
    "merged_data = merged_data.dropna(subset=[\"RmsId\"])\n",
    "merged_data[\"RmsId\"] = merged_data[\"RmsId\"].astype(int)\n",
    "\n",
    "# Remove duplicates if necessary\n",
    "merged_data_unique = merged_data.drop_duplicates(subset='EB_SPWebUrl_cleaned')\n",
    "merged_data_unique.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FileSystemObjectType', 'Id', 'ServerRedirectedEmbedUri',\n",
       "       'ServerRedirectedEmbedUrl', 'ID', 'ContentTypeId', 'Title', 'Modified',\n",
       "       'Created', 'AuthorId', 'EditorId', 'OData__UIVersionString',\n",
       "       'Attachments', 'GUID', 'ComplianceAssetId', 'EB_Created', 'EB_ID',\n",
       "       'EB_ListID', 'EB_SiteID', 'EB_SiteTitle', 'EB_SPWebUrl', 'EB_Url',\n",
       "       'FlowLog', 'EB_UniqueID', 'EB_Author', 'OData__ColorTag', 'EB_NoteType',\n",
       "       'EB_SPWebUrl_cleaned', 'SharePointLinkTruncated_cleaned', 'RmsId',\n",
       "       'Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_unique.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Offerings (Prospectuses) From SharePoint Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new files to download for RmsId 127 at /sites/Faurecia73/Reorg/\n",
      "No new files to download for RmsId 287 at /sites/4692/Reorg/\n",
      "No new files to download for RmsId 12 at /sites/12/Reorg/\n",
      "No new files to download for RmsId 312 at /sites/Axilone77/Reorg/\n",
      "No new files to download for RmsId 135 at /sites/135/Reorg/\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Skip rows where there is no matching RmsId\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Download files; the function will create the folder only if files are downloaded\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mdownload_specific_files_for_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_document_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_document_subtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 98\u001b[0m, in \u001b[0;36mdownload_specific_files_for_row\u001b[1;34m(row, desired_document_type, desired_document_subtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# Get files with metadata in the folder\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     files \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_files_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_relative_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[0;32m    100\u001b[0m         list_item_properties \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mlistItemAllFields\u001b[38;5;241m.\u001b[39mproperties\n",
      "Cell \u001b[1;32mIn[2], line 107\u001b[0m, in \u001b[0;36mCustomSharePoint.get_files_metadata\u001b[1;34m(self, folder_url)\u001b[0m\n\u001b[0;32m    105\u001b[0m folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx\u001b[38;5;241m.\u001b[39mweb\u001b[38;5;241m.\u001b[39mget_folder_by_server_relative_url(folder_url)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Expand to include ListItemAllFields to access metadata\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m files_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mfolder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mListItemAllFields\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m files_metadata\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\site-packages\\office365\\runtime\\client_object.py:55\u001b[0m, in \u001b[0;36mClientObject.execute_query\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_query\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# type: () -> Self\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Submit request(s) to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\site-packages\\office365\\runtime\\client_runtime_context.py:173\u001b[0m, in \u001b[0;36mClientRuntimeContext.execute_query\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_pending_request:\n\u001b[0;32m    172\u001b[0m     qry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_next_query()\n\u001b[1;32m--> 173\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpending_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\site-packages\\office365\\runtime\\client_request.py:37\u001b[0m, in \u001b[0;36mClientRequest.execute_query\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(query)\n\u001b[1;32m---> 37\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_request_direct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response(response, query)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafterExecute\u001b[38;5;241m.\u001b[39mnotify(response)\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\site-packages\\office365\\runtime\\client_request.py:93\u001b[0m, in \u001b[0;36mClientRequest.execute_request_direct\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     84\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mput(\n\u001b[0;32m     85\u001b[0m         url\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m     86\u001b[0m         data\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mdata,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mproxies,\n\u001b[0;32m     91\u001b[0m     )\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\site-packages\\urllib3\\connection.py:507\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    510\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\http\\client.py:1375\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1375\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1376\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\socket.py:717\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    719\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\ssl.py:1307\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1304\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1305\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1306\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\pih\\AppData\\Local\\miniconda3\\envs\\capfourpy\\lib\\ssl.py:1163\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the desired metadata values\n",
    "desired_document_type = \"Legal\"\n",
    "desired_document_subtype = \"Offerings\"\n",
    "\n",
    "# Create a dictionary to store CustomSharePoint instances\n",
    "sp_instances = {}\n",
    "\n",
    "# Process each row in the merged dataframe\n",
    "for index, row in merged_data_unique.iterrows():\n",
    "    if pd.isna(row['RmsId']):\n",
    "        continue  # Skip rows where there is no matching RmsId\n",
    "    # Download files; the function will create the folder only if files are downloaded\n",
    "    download_specific_files_for_row(row, desired_document_type, desired_document_subtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List of `RmsId` that does have Fundamental Score but does not have Findox Offering PDF** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 5, 10, 12, 13, 14, 17, 20, 24, 32, 33, 35, 37, 40, 41, 46, 51, 52, 55, 56, 63, 65, 66, 68, 74, 75, 78, 80, 81, 83, 84, 86, 89, 95, 98, 105, 112, 116, 120, 128, 132, 134, 135, 140, 143, 145, 147, 149, 153, 159, 160, 161, 168, 171, 174, 178, 183, 185, 196, 200, 209, 218, 223, 224, 225, 227, 229, 232, 236, 238, 241, 242, 246, 249, 257, 263, 265, 268, 271, 273, 274, 275, 278, 279, 280, 282, 291, 293, 295, 296, 300, 301, 302, 305, 307, 309, 311, 312, 316, 319, 323, 324, 327, 329, 331, 333, 335, 339, 342, 344, 345, 349, 355, 356, 358, 360, 362, 370, 372, 374, 376, 384, 385, 400, 413, 414, 420, 428, 431, 432, 438, 451, 453, 454, 488, 489, 496, 499, 508, 512, 517, 518, 593, 613, 614, 615, 616, 621, 622, 626, 634, 639, 645, 646, 647, 648, 649, 653, 654, 655, 659, 662, 663, 664, 672, 673, 674, 675, 679, 680, 682, 683, 684, 765, 767, 768, 772, 816, 839, 845, 884, 901, 904, 905, 906, 907, 908, 911, 913, 917, 920, 924, 935, 936, 945, 946, 947, 948, 949, 950, 951, 953, 954, 976, 986, 987, 988, 990, 991, 993, 996, 998, 1003, 1004, 1006, 1009, 1015, 1016, 1020, 1022, 1028, 1029, 1032, 1034, 1037, 1041, 1045, 1046, 1047, 1049, 1051, 1054, 1055, 1056, 1057, 1058, 1060, 1063, 1064, 1066, 1067, 1069, 1070, 1071, 1072, 1073, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1095, 1097, 1098, 1099, 1101, 1104, 1105, 1106, 1109, 1126, 1127, 1130, 1132, 1133, 1134, 1138, 1141, 1146, 1150, 1153, 1159, 1182, 1188, 1197, 1220, 1221, 1222, 1247, 1249, 1261, 1281, 1283, 1284, 1285, 1314, 1355, 1365, 1456, 1474, 1475, 1480, 1490, 1495, 1512, 1524, 1525, 1529, 1535, 1536, 1539, 1540, 1542, 1547, 1555, 1558, 1560, 1563, 1564, 1565, 1568, 1592, 1609, 1613, 1615, 1616, 1617, 1618, 1634, 1639, 1654, 1662, 1666, 1669, 1670, 1691, 1700, 1709, 1710, 1720, 1730, 1733, 1749, 1750, 1766, 1767, 1768, 1778, 1792, 1796, 1797, 1801, 1802, 1803, 1807, 1809, 1845, 1868, 1889, 1900, 1916, 1920, 1923, 1931, 1960, 1961, 1994, 2101, 2118, 2124, 2125, 2128, 2140, 2145, 2178, 2187]\n"
     ]
    }
   ],
   "source": [
    "# Print the list of RmsId that does not have Prospectus\n",
    "sorted_rms_id_df = merged_data_unique[[\"RmsId\"]].sort_values(by=\"RmsId\").reset_index(drop=True)\n",
    "rms_id_list = sorted_rms_id_df[\"RmsId\"].to_list()\n",
    "\n",
    "directory_path = \"../data/raw/sharepoint_reorg_files/\"\n",
    "# Get list of RmsId folders that actually exist in the directory\n",
    "existing_folders = [int(folder) for folder in os.listdir(directory_path) if folder.isdigit() and int(folder) in rms_id_list]\n",
    "\n",
    "# List of RmsId that do not have an associated folder\n",
    "rms_id_without_folders = [rms_id for rms_id in rms_id_list if rms_id not in existing_folders]\n",
    "print(rms_id_without_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capfourpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
